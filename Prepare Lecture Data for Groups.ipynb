{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6505c75",
   "metadata": {},
   "source": [
    "### Create Lecure based factors to use in Matching Experiment\n",
    "\n",
    "Length of lectures, start time, teacher competencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8fdd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sas7bdat\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1901b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lec_group=pd.read_pickle('../Data/lektionhold.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3640c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lec=pd.read_pickle('../Data/lektioner.pkl')\n",
    "\n",
    "#Add lesson data to the lesson groups. \n",
    "lec.drop(columns=['date','lokale','gennemfrt'],inplace=True)\n",
    "test=lec_group.merge(lec,on=['inst_nr','lektions_nr'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faecddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get teacher data for lessons\n",
    "filepath='../data/macom_lektionerlaerer.sas7bdat'\n",
    "teachers =pd.read_sas(filepath, format='sas7bdat',encoding='iso-8859-1')\n",
    "\n",
    "#Clean columns\n",
    "teachers.rename(columns={'InstNr':'inst_nr','LektionsNr':'lektions_nr'},inplace=True)\n",
    "print(len(test))\n",
    "#Merge\n",
    "test=test.merge(teachers,on=['inst_nr','lektions_nr'],how='left')\n",
    "print(len(test))\n",
    "\n",
    "df=test[~test['laerer_id'].isna()]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d82b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The courses from umo\n",
    "filepath='../data/umo_fag.sas7bdat'\n",
    "course =pd.read_sas(filepath, format='sas7bdat',encoding='iso-8859-1')\n",
    "\n",
    "#Keep only relevant columns and rename others\n",
    "course=course[['Fag','KortBetegnelse']]\n",
    "course.rename(columns={'Fag':'fag_nr','KortBetegnelse':'course'},inplace=True)\n",
    "\n",
    "#Add description to courses based on descrption and add hard_science\n",
    "course_description=pd.read_excel('course_description.xlsx')\n",
    "course=course.merge(course_description,on='course',how='left')\n",
    "\n",
    "print(len(course))\n",
    "course=course[~course['hard_science'].isna()]\n",
    "print(len(course))\n",
    "course.drop_duplicates(inplace=True)\n",
    "print(len(course))\n",
    "\n",
    "#Add descriptions to the df to allow merge with teacher competencies \n",
    "new_df=df.merge(course,on='fag_nr',how='left')\n",
    "print(len(new_df['course'].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9090b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Macom competencies data from SAS file\n",
    "filepath = '../data/macom_kompetencer.sas7bdat'\n",
    "komp = pd.read_sas(filepath, format='sas7bdat', encoding='iso-8859-1')\n",
    "komp.rename(columns={'InstNr': 'inst_nr', 'KompetenceNiveau': 'competency'}, inplace=True)\n",
    "\n",
    "# Read the descriptions for competency codes from Excel file\n",
    "komp_descr = pd.read_excel('../Data/komp_koder.xlsx')\n",
    "komp_descr.drop(columns=['Bekendtg√∏relsesafsnit', 'Kompetence betegnelse', 'AGYM', 'EGYM', 'Niveau', 'Fag'], inplace=True)\n",
    "komp_descr.rename(columns={'Fagkode': 'fag_nr', 'Kompetencekode': 'KompetenceKode'}, inplace=True)\n",
    "\n",
    "# Merge the competency codes with their descriptions\n",
    "komp = komp.merge(komp_descr, on='KompetenceKode', how='left')\n",
    "\n",
    "# Drop the unnecessary columns from the merged DataFrame\n",
    "komp.drop(columns='KompetenceKode', inplace=True)\n",
    "\n",
    "# Merge the course names with the teacher competencies\n",
    "new_komp = komp.merge(course, on='fag_nr', how='left')\n",
    "\n",
    "# Fill NA values in the competency column with 'unknown'\n",
    "komp['competency'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Map the course competencies as binary values (1: competent, 0: not competent)\n",
    "new_komp['competency'] = new_komp['competency'].astype(str)\n",
    "competency_map = {'U': 1, 'F': 1, 'P': 0, 'I': 0}\n",
    "new_komp['competency'] = new_komp['competency'].map(competency_map).fillna(0)\n",
    "\n",
    "# Drop unnecessary columns from the new_komp DataFrame\n",
    "new_komp.drop(columns=['fag_nr', 'hard_science'], inplace=True)\n",
    "\n",
    "# Drop duplicate rows in the new_komp DataFrame\n",
    "new_komp.drop_duplicates(inplace=True)\n",
    "\n",
    "# Group the new_komp DataFrame by teacher, course, and institution number\n",
    "grouped_komp = new_komp.groupby(['laerer_id', 'course', 'inst_nr'])\n",
    "\n",
    "# Find the maximum competency value for each group\n",
    "max_competency = grouped_komp['competency'].max()\n",
    "\n",
    "# Reset the index of the max_competency DataFrame\n",
    "max_competency = max_competency.reset_index()\n",
    "\n",
    "# Merge the new_df DataFrame with the max_competency DataFrame based on teacher, course, and institution number\n",
    "merged_df = new_df.merge(max_competency, on=['laerer_id', 'course', 'inst_nr'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168272ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = new_df.merge(new_komp, on=['laerer_id', 'course','inst_nr'], how='left')\n",
    "\n",
    "temp =(merged_df.groupby(['hold_nr','start_time','end_time'],sort=False)\n",
    "              .agg(**{'lektioner' :('lektions_nr','nunique')})\n",
    "              .reset_index()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'hold_nr' and 'start_time' and reset the index\n",
    "df = temp.copy()\n",
    "df = df.sort_values(by=['hold_nr', 'start_time']).reset_index(drop=True)\n",
    "\n",
    "# Check if the start time of the next row is within forty minutes of the end time of the current row.\n",
    "# If so, update to the same 'block_id'. Otherwise, assign a new 'block_id' and increment the count.\n",
    "def check_if_block_optimized(df):\n",
    "    def update_block_id(row):\n",
    "        nonlocal count\n",
    "        if row['next_start_time'] < row['end_time'] + pd.Timedelta(minutes=40) and row['hold_nr'] == row['next_hold_nr']:\n",
    "            block_id = count\n",
    "        else:\n",
    "            block_id = count\n",
    "            count += 1\n",
    "        return block_id\n",
    "\n",
    "    count = 0\n",
    "    # Create new columns 'next_start_time' and 'next_hold_nr' by shifting values of 'start_time' and 'hold_nr'\n",
    "    df['next_start_time'] = df['start_time'].shift(-1)\n",
    "    df['next_hold_nr'] = df['hold_nr'].shift(-1)\n",
    "\n",
    "    # Apply the 'update_block_id' function to calculate the 'block_id' based on the conditions\n",
    "    df['block_id'] = df.apply(update_block_id, axis=1)\n",
    "\n",
    "    # Drop the temporary columns 'next_start_time' and 'next_hold_nr'\n",
    "    df.drop(columns=['next_start_time', 'next_hold_nr'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['block_id']=0\n",
    "#Aplly function from above\n",
    "updated_df = check_if_block_optimized(df)\n",
    "updated_df.drop(columns=['lektioner'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge back the updated to add block id\n",
    "merged_df=merged_df.merge(updated_df,on=['hold_nr','start_time','end_time'],how='left')\n",
    "merged_df=merged_df.sort_values(by=['hold_nr', 'start_time']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace9d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Gennemrfrt they are all completed anywats\n",
    "merged_df.loc[~merged_df['laerer_id'].isin(new_komp['laerer_id']), 'competency'] = 'unknown'\n",
    "merged_df['competency'].fillna('no', inplace=True)\n",
    "\n",
    "# Group by hold_nr and block_id, then aggregate using the earliest start_time and latest end_time\n",
    "result = merged_df.groupby(['hold_nr', 'inst_nr', 'block_id','fag_nr','niveau',\n",
    "                             'hard_science','laerer_id','competency'\n",
    "                            ]).agg(\n",
    "    start_time=('start_time', 'min'),\n",
    "    end_time=('end_time', 'max'),\n",
    "    minutters_undervisning=('minutters_undervisning','sum')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cbaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the school year based on the 'end_date' column\n",
    "result['hold_nr']=result['hold_nr'].astype(float)\n",
    "result['school_year'] = result['start_time'].dt.year\n",
    "result.loc[result['start_time'].dt.month < 7, 'school_year'] -= 1\n",
    "\n",
    "# Extract the last two digits of the school year\n",
    "result['school_year_suffix'] = result['school_year'] % 100\n",
    "\n",
    "# Append the school year suffix to the hold_nr column\n",
    "result['new_holdnr'] = result['hold_nr'] + result['school_year_suffix'] / 100\n",
    "\n",
    "result=result[result['block_id'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'new_holdnr' and 'block_id' and aggregate 'laerer_id' as a list\n",
    "grouped_df =result.groupby(['new_holdnr', 'block_id'])['laerer_id'].agg(list).reset_index()\n",
    "\n",
    "# Sort the values by 'block_id'\n",
    "grouped_df = grouped_df.sort_values('block_id')\n",
    "\n",
    "#Save sorted_df as what grouped_df was at this moment :) \n",
    "sorted_df=grouped_df.copy()\n",
    "\n",
    "# Drop duplicates in 'new_holdnr' column, keeping only the first instance\n",
    "grouped_df = grouped_df.drop_duplicates(subset='new_holdnr', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe04032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'teacher_change' in the non-aggregated DataFrame\n",
    "sorted_df['teacher_change'] = 0\n",
    "\n",
    "# Convert grouped_df to a dictionary\n",
    "teacher_sets = dict(zip(grouped_df['new_holdnr'], grouped_df['laerer_id']))\n",
    "\n",
    "# Iterate through the rows of the non-aggregated DataFrame\n",
    "for index in sorted_df.index:\n",
    "    new_holdnr = sorted_df.loc[index, 'new_holdnr']\n",
    "    laerer_id_list = sorted_df.loc[index, 'laerer_id']\n",
    "\n",
    "    # Check if any teacher in the 'laerer_id' list is present in 'teacher_sets'\n",
    "    teacher_in_set = any(teacher in teacher_sets[(new_holdnr)] for teacher in laerer_id_list)\n",
    "\n",
    "    # If none of the teachers are present, set 'teacher_change' to 1 and add the entire 'laerer_id' list to 'teacher_sets'\n",
    "    if not teacher_in_set:\n",
    "        sorted_df.at[index, 'teacher_change'] = 1\n",
    "        teacher_sets[(new_holdnr)].extend(laerer_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6584ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the sum of teacher changes \n",
    "teacher_changes=(sorted_df.groupby(['new_holdnr'],sort=False)\n",
    "              .agg(**{'teacher_changes': ('teacher_change','sum')})\n",
    "              .reset_index()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcaa7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-3, 3))\n",
    "\n",
    "# Reshape the \"rounded_start\" values to a 2D array for scaling\n",
    "values = hours['rounded_start'].values.reshape(-1, 1)\n",
    "\n",
    "# Scale the values using the MinMaxScaler\n",
    "scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "# Assign the scaled values to a new column \"normalized_start\"\n",
    "hours['normalized_start'] = scaled_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f79277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the starttime of lectures and use it to scale, positive means later or ealier \n",
    "hours = result.drop_duplicates(subset=['new_holdnr', 'block_id'])\n",
    "\n",
    "hours['rounded_start'] = hours['start_time'].dt.round('H').dt.hour.astype(np.int)\n",
    "\n",
    "hours=hours.query('rounded_start > 7 & rounded_start < 17')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-3, 3))\n",
    "\n",
    "# Reshape the \"rounded_start\" values to a 2D array for scaling\n",
    "values = hours['rounded_start'].values.reshape(-1, 1)\n",
    "\n",
    "# Scale the values using the MinMaxScaler\n",
    "scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "# Assign the scaled values to a new column \"normalized_start\"\n",
    "hours['normalized_start'] = scaled_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce437ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute values of the normalized values\n",
    "abs_values = np.abs(hours['normalized_start'])\n",
    "\n",
    "# Scale the absolute values between 0 and 3\n",
    "scaled_abs_values = (abs_values / abs_values.max()) * 3\n",
    "\n",
    "# Assign the scaled absolute values to a new column \"abs_normalized_start\"\n",
    "hours['abs_normalized_start'] = scaled_abs_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get sum of hours for group, avg amount hour, avg start, avg start scaled\n",
    "hours = (hours.groupby(['new_holdnr'], sort=False)\n",
    "              .agg(**{'sum_hours': ('minutters_undervisning', 'sum'),\n",
    "                      'avg_hours': ('minutters_undervisning', 'mean'),\n",
    "                      'avg_start': ('rounded_start', 'mean'),\n",
    "                     'avg_start_scaled' : ('abs_normalized_start','mean')})\n",
    "              .reset_index()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12484594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'new_holdnr' and 'block_id' and aggregate 'laerer_id' as a list\n",
    "grouped_lesson =result.groupby(['new_holdnr'])['laerer_id'].agg(set).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either competency or not\n",
    "result['competency'] = np.where(result['competency']  != 1, 0, result['competency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First group to get if a single teacher has a competency in the course, next get the mean. This is necessary to deal with\n",
    "#multi-teachers\n",
    "final=(result.groupby(['new_holdnr','block_id'],sort=False)\n",
    "              .agg(**{'competencies': ('competency','max')})\n",
    "              .reset_index()\n",
    "              )\n",
    "\n",
    "final=(final.groupby(['new_holdnr'],sort=False)\n",
    "              .agg(**{'competencies': ('competencies','mean')})\n",
    "              .reset_index()\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23010460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add both teacher changes, grouped lessons and start hours to the final data frame which contains competencies\n",
    "merged_final=final.merge(grouped_lesson,on='new_holdnr').merge(hours,on='new_holdnr').merge(teacher_changes, on='new_holdnr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_final.to_pickle('../df/group_meta.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b33e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
