{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b256f3",
   "metadata": {},
   "source": [
    "### Here we calculate the Euclidean Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73722956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 13\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 11\n",
    "mpl.rcParams['ytick.labelsize'] = 11\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.prop_cycle'] = plt.cycler('color', plt.cm.Set1.colors)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = '#f8f8f8'\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4711bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "students=pd.read_pickle('../df/group_regression.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c97a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Columns we coul not get teacher info on. \n",
    "df=students[~students['teacher_changes'].isna()]\n",
    "\n",
    "#We only want groups of realistic sizes\n",
    "df=df[(df['students'] > 8) & (df['students'] < 36)]\n",
    "\n",
    "#Change gradetype to a binary variable exam, true or False\n",
    "df['KarakterType']=df['KarakterType'].astype(str)\n",
    "df['exam'] = df['KarakterType'].replace({'Ã…RS': 0, 'STA': 0, 'EKS': 1, 'IPR': 1})\n",
    "df.drop(columns='KarakterType',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50731f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Dummy columns for the Evaluation form\n",
    "df['EvaleringsForm']=df['EvaleringsForm'].astype(str)\n",
    "\n",
    "dummy_cols = pd.get_dummies(df['EvaleringsForm'])\n",
    "\n",
    "# Rename the dummy columns\n",
    "dummy_cols = dummy_cols.rename(columns={'MDT': 'Oral', 'SKR': 'Written', 'SAM': 'Colab'})\n",
    "\n",
    "# Concatenate the dummy columns with the original DataFrame\n",
    "df = pd.concat([df, dummy_cols], axis=1)\n",
    "\n",
    "#Drop the Original Evaluation Form column\n",
    "df.drop(columns=['EvaleringsForm'],inplace=True)\n",
    "\n",
    "#Fill with most common since basically zero nan \n",
    "df['aarsag']=df['aarsag'].fillna(df['aarsag'].value_counts().index[0])\n",
    "\n",
    "#Change reason to a binary variable to show if it is mandatory 1 = true\n",
    "df['aarsag']=df['aarsag'].astype(str)\n",
    "df['mandatory'] = df['aarsag'].replace({'FRIVALG': 0, 'OBLIFAG': 1,'OBLFAG':1, 'STUDRET': 1})\n",
    "df.drop(columns=['aarsag'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c4bc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode subject level since I don't assume linear relationship \n",
    "one_hot_encoded = pd.get_dummies(df['fag_niveau'], prefix='level')\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "df= pd.concat([df, one_hot_encoded], axis=1)\n",
    "\n",
    "df.rename(columns={'level_-':'level_none'},inplace=True)\n",
    "df.drop(columns=['fag_niveau'],inplace=True)\n",
    "\n",
    "#Log the teacher changes \n",
    "df['teacher_changes']=np.log(df['teacher_changes']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0788b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import zscore \n",
    "\n",
    "new_df=df.copy()\n",
    "\n",
    "#Define function to remove outliers for certain columns\n",
    "def z_score_normalize(df, column_names, threshold):\n",
    "    for column_name in column_names:\n",
    "        # Calculate mean and standard deviation\n",
    "        mean = df[column_name].mean()\n",
    "        std = df[column_name].std()\n",
    "\n",
    "        # Compute z-scores\n",
    "        z_scores = zscore(df[column_name])\n",
    "\n",
    "        # Identify outliers based on threshold\n",
    "        outliers = df[abs(z_scores) > threshold]\n",
    "\n",
    "        # Remove outliers from DataFrame\n",
    "        df = df.drop(outliers.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "columns_to_normalize = ['income_father', 'income_mother','avg_hours','sum_hours','percent',\n",
    "                       'income_mothers','income_fathers','age']\n",
    "new_df = z_score_normalize(new_df, columns_to_normalize,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "cols_to_normalize=['avg_hours','avg_start','income_mother','income_father','edu_mothers','edu_fathers',\n",
    "                    'edu_level_mother','edu_level_father','avg_grade','group_grade','percent','sum_hours',\n",
    "                  'students_avg_grde','income_mothers','income_fathers', 'age']\n",
    "\n",
    "# Define the range to scale the values to\n",
    "min_value = -3\n",
    "max_value = 3\n",
    "\n",
    "# Create a MinMaxScaler object and fit it to the data\n",
    "scaler = MinMaxScaler(feature_range=(min_value, max_value))\n",
    "scaler.fit(new_df[cols_to_normalize])\n",
    "\n",
    "# Transform the data using the scaler for relevant columns\n",
    "new_df[cols_to_normalize] = scaler.transform(new_df[cols_to_normalize])\n",
    "\n",
    "\n",
    "male=new_df.query('gender==0')\n",
    "female=new_df.query('gender==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb41ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First pair calculation, student pairs without average grade matching\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "# Filter the DataFrame based on course and step\n",
    "student_df = new_df[new_df['step'] == 3]\n",
    "\n",
    "# Select the columns of interest and the elev_id column\n",
    "columns_of_interest = ['edu_level_mother', 'gender', 'income_mother', 'age', 'income_father', 'edu_level_father']\n",
    "sub_df = student_df[['elev_id'] + columns_of_interest]\n",
    "sub_df.drop_duplicates(subset='elev_id', inplace=True)\n",
    "\n",
    "# Set the index of the DataFrame to 'elev_id'\n",
    "sub_df.set_index('elev_id', inplace=True)\n",
    "\n",
    "# Loop over each edu_level_mother and calculate pairwise distances to save memory\n",
    "edu_levels = sub_df['edu_level_mother'].unique()\n",
    "result_df_list = []\n",
    "for i, edu_level in enumerate(edu_levels):\n",
    "    print(f'Processing edu_level_mother {edu_level}. {i+1}/{len(edu_levels)}')\n",
    "    \n",
    "    # Filter the DataFrame to keep only the current edu_level_mother\n",
    "    edu_level_df = sub_df[sub_df['edu_level_mother'] == edu_level]\n",
    "    \n",
    "    # Compute pairwise distances between rows\n",
    "    print('  Calculating distance matrix...')\n",
    "    dist_matrix = pairwise_distances(edu_level_df[columns_of_interest], metric='euclidean')\n",
    "    \n",
    "    # Convert the pairwise distances to a square distance matrix\n",
    "    df_euclid = pd.DataFrame(dist_matrix, index=edu_level_df.index, columns=edu_level_df.index)\n",
    "    \n",
    "    # Filter the matrix to exclude pairs that are too far apart\n",
    "    df_euclid[df_euclid > 0.5] = np.nan\n",
    "\n",
    "    # Loop over each row in the matrix and create a DataFrame of the pairs and distances\n",
    "    print('  Creating pairs DataFrame...')\n",
    "    pairs_df_list = []\n",
    "    for index, row in df_euclid.iterrows():\n",
    "        row_df = pd.DataFrame({\n",
    "            'elev_id': index,\n",
    "            'neighbour': row.index,\n",
    "            'distance': row\n",
    "        })\n",
    "        row_df.dropna(inplace=True)\n",
    "        row_df = row_df[row_df['elev_id'] != row_df['neighbour']]\n",
    "        pairs_df_list.append(row_df)\n",
    "    \n",
    "    # Concatenate the DataFrames for all rows into a single DataFrame for the edu_level_mother\n",
    "    print('  Concatenating pairs DataFrames...')\n",
    "    edu_level_df_pairs = pd.concat(pairs_df_list, ignore_index=True)\n",
    "    edu_level_df_pairs.sort_values('distance', inplace=True)\n",
    "    \n",
    "    # Add the result to the list\n",
    "    result_df_list.append(edu_level_df_pairs)\n",
    "\n",
    "# Concatenate the result DataFrames\n",
    "no_grade = pd.concat(result_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ea1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_grade.to_pickle('../distance/no_grade.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second pair calculation, student pairs with average grade, step 3\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Filter the DataFrame based on course and step\n",
    "student_df = new_df[new_df['step'] == 3]\n",
    "\n",
    "# Select the columns of interest and the elev_id column\n",
    "columns_of_interest = ['edu_level_mother', 'gender', 'income_mother', 'age', 'income_father', 'edu_level_father', 'avg_grade']\n",
    "sub_df = student_df[['elev_id'] + columns_of_interest]\n",
    "sub_df.drop_duplicates(subset='elev_id', inplace=True)\n",
    "\n",
    "# Set the index of the DataFrame to 'elev_id'\n",
    "sub_df.set_index('elev_id', inplace=True)\n",
    "\n",
    "# Loop over each edu_level_mother and calculate pairwise distances\n",
    "edu_levels = sub_df['edu_level_mother'].unique()\n",
    "result_df_list = []\n",
    "for i, edu_level in enumerate(edu_levels):\n",
    "    print(f'Processing edu_level_mother {edu_level}. {i+1}/{len(edu_levels)}')\n",
    "    \n",
    "    # Filter the DataFrame to keep only the current edu_level_mother\n",
    "    edu_level_df = sub_df[sub_df['edu_level_mother'] == edu_level]\n",
    "    \n",
    "    # Compute pairwise distances between rows\n",
    "    print('  Calculating distance matrix...')\n",
    "    dist_matrix = pairwise_distances(edu_level_df[columns_of_interest], metric='euclidean')\n",
    "    \n",
    "    # Convert the pairwise distances to a square distance matrix\n",
    "    df_euclid = pd.DataFrame(dist_matrix, index=edu_level_df.index, columns=edu_level_df.index)\n",
    "    \n",
    "    # Filter the matrix to exclude pairs that are too far apart\n",
    "    df_euclid[df_euclid > 0.5] = np.nan\n",
    "\n",
    "    # Loop over each row in the matrix and create a DataFrame of the pairs and distances\n",
    "    print('  Creating pairs DataFrame...')\n",
    "    pairs_df_list = []\n",
    "    for index, row in df_euclid.iterrows():\n",
    "        row_df = pd.DataFrame({\n",
    "            'elev_id': index,\n",
    "            'neighbour': row.index,\n",
    "            'distance': row\n",
    "        })\n",
    "        row_df.dropna(inplace=True)\n",
    "        row_df = row_df[row_df['elev_id'] != row_df['neighbour']]\n",
    "        pairs_df_list.append(row_df)\n",
    "    \n",
    "    # Concatenate the DataFrames for all rows into a single DataFrame for the edu_level_mother\n",
    "    print('  Concatenating pairs DataFrames...')\n",
    "    edu_level_df_pairs = pd.concat(pairs_df_list, ignore_index=True)\n",
    "    edu_level_df_pairs.sort_values('distance', inplace=True)\n",
    "    \n",
    "    # Add the result to the list\n",
    "    result_df_list.append(edu_level_df_pairs)\n",
    "\n",
    "# Concatenate the result DataFrames\n",
    "result_df3 = pd.concat(result_df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third pair calculation, student pairs with average grade, step 2\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Filter the DataFrame based on course and step\n",
    "student_df = new_df[new_df['step'] == 2]\n",
    "\n",
    "# Select the columns of interest and the elev_id column\n",
    "columns_of_interest = ['edu_level_mother', 'gender', 'income_mother', 'age', 'income_father', 'edu_level_father', 'avg_grade']\n",
    "sub_df = student_df[['elev_id'] + columns_of_interest]\n",
    "sub_df.drop_duplicates(subset='elev_id', inplace=True)\n",
    "\n",
    "# Set the index of the DataFrame to 'elev_id'\n",
    "sub_df.set_index('elev_id', inplace=True)\n",
    "\n",
    "# Loop over each edu_level_mother and calculate pairwise distances\n",
    "edu_levels = sub_df['edu_level_mother'].unique()\n",
    "result_df_list = []\n",
    "for i, edu_level in enumerate(edu_levels):\n",
    "    print(f'Processing edu_level_mother {edu_level}. {i+1}/{len(edu_levels)}')\n",
    "    \n",
    "    # Filter the DataFrame to keep only the current edu_level_mother\n",
    "    edu_level_df = sub_df[sub_df['edu_level_mother'] == edu_level]\n",
    "    \n",
    "    # Compute pairwise distances between rows\n",
    "    print('  Calculating distance matrix...')\n",
    "    dist_matrix = pairwise_distances(edu_level_df[columns_of_interest], metric='euclidean')\n",
    "    \n",
    "    # Convert the pairwise distances to a square distance matrix\n",
    "    df_euclid = pd.DataFrame(dist_matrix, index=edu_level_df.index, columns=edu_level_df.index)\n",
    "    \n",
    "    # Filter the matrix to exclude pairs that are too far apart\n",
    "    df_euclid[df_euclid > 0.5] = np.nan\n",
    "\n",
    "    # Loop over each row in the matrix and create a DataFrame of the pairs and distances\n",
    "    print('  Creating pairs DataFrame...')\n",
    "    pairs_df_list = []\n",
    "    for index, row in df_euclid.iterrows():\n",
    "        row_df = pd.DataFrame({\n",
    "            'elev_id': index,\n",
    "            'neighbour': row.index,\n",
    "            'distance': row\n",
    "        })\n",
    "        row_df.dropna(inplace=True)\n",
    "        row_df = row_df[row_df['elev_id'] != row_df['neighbour']]\n",
    "        pairs_df_list.append(row_df)\n",
    "    \n",
    "    # Concatenate the DataFrames for all rows into a single DataFrame for the edu_level_mother\n",
    "    print('  Concatenating pairs DataFrames...')\n",
    "    edu_level_df_pairs = pd.concat(pairs_df_list, ignore_index=True)\n",
    "    edu_level_df_pairs.sort_values('distance', inplace=True)\n",
    "    \n",
    "    # Add the result to the list\n",
    "    result_df_list.append(edu_level_df_pairs)\n",
    "\n",
    "# Concatenate the result DataFrames\n",
    "result_df2 = pd.concat(result_df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c30fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourth pair calculation, student pairs with average grade, step 1\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Filter the DataFrame based on course and step\n",
    "student_df = new_df[new_df['step'] == 1]\n",
    "\n",
    "# Select the columns of interest and the elev_id column\n",
    "columns_of_interest = ['edu_level_mother', 'gender', 'income_mother', 'age', 'income_father', 'edu_level_father', 'avg_grade']\n",
    "sub_df = student_df[['elev_id'] + columns_of_interest]\n",
    "sub_df.drop_duplicates(subset='elev_id', inplace=True)\n",
    "\n",
    "# Set the index of the DataFrame to 'elev_id'\n",
    "sub_df.set_index('elev_id', inplace=True)\n",
    "\n",
    "# Loop over each edu_level_mother and calculate pairwise distances\n",
    "edu_levels = sub_df['edu_level_mother'].unique()\n",
    "result_df_list = []\n",
    "for i, edu_level in enumerate(edu_levels):\n",
    "    print(f'Processing edu_level_mother {edu_level}. {i+1}/{len(edu_levels)}')\n",
    "    \n",
    "    # Filter the DataFrame to keep only the current edu_level_mother\n",
    "    edu_level_df = sub_df[sub_df['edu_level_mother'] == edu_level]\n",
    "    \n",
    "    # Compute pairwise distances between rows\n",
    "    print('  Calculating distance matrix...')\n",
    "    dist_matrix = pairwise_distances(edu_level_df[columns_of_interest], metric='euclidean')\n",
    "    \n",
    "    # Convert the pairwise distances to a square distance matrix\n",
    "    df_euclid = pd.DataFrame(dist_matrix, index=edu_level_df.index, columns=edu_level_df.index)\n",
    "    \n",
    "    # Filter the matrix to exclude pairs that are too far apart\n",
    "    df_euclid[df_euclid > 0.5] = np.nan\n",
    "\n",
    "    # Loop over each row in the matrix and create a DataFrame of the pairs and distances\n",
    "    print('  Creating pairs DataFrame...')\n",
    "    pairs_df_list = []\n",
    "    for index, row in df_euclid.iterrows():\n",
    "        row_df = pd.DataFrame({\n",
    "            'elev_id': index,\n",
    "            'neighbour': row.index,\n",
    "            'distance': row\n",
    "        })\n",
    "        row_df.dropna(inplace=True)\n",
    "        row_df = row_df[row_df['elev_id'] != row_df['neighbour']]\n",
    "        pairs_df_list.append(row_df)\n",
    "    \n",
    "    # Concatenate the DataFrames for all rows into a single DataFrame for the edu_level_mother\n",
    "    print('  Concatenating pairs DataFrames...')\n",
    "    edu_level_df_pairs = pd.concat(pairs_df_list, ignore_index=True)\n",
    "    edu_level_df_pairs.sort_values('distance', inplace=True)\n",
    "    \n",
    "    # Add the result to the list\n",
    "    result_df_list.append(edu_level_df_pairs)\n",
    "\n",
    "# Concatenate the result DataFrames\n",
    "result_df1 = pd.concat(result_df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119206d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all the results to use in Regression Matched Pair Analysis\n",
    "result_df1.to_pickle('../distance/results1.pkl')\n",
    "result_df2.to_pickle('../distance/results2.pkl')\n",
    "result_df3.to_pickle('../distance/results3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801830e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_pickle('../distance/gen_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
