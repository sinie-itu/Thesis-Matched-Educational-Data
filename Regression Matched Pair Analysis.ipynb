{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6f5c3a",
   "metadata": {},
   "source": [
    "### Results from the student pair analysis \n",
    "\n",
    "The dataframes created for this are created in the \"Prep Group Grade\" and \"Prep Lecture Grade\" Files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.style.use('seaborn-whitegrid')  # Use 'seaborn-whitegrid' instead of 'ggplot'\n",
    "\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 13\n",
    "mpl.rcParams['axes.titlesize'] = 16\n",
    "mpl.rcParams['xtick.labelsize'] = 11\n",
    "mpl.rcParams['ytick.labelsize'] = 11\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.prop_cycle'] = plt.cycler('color', plt.cm.Set1.colors)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = '#f8f8f8'\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#General df, info on students\n",
    "gen_df=pd.read_pickle('../distance/gen_df.pkl')\n",
    "gen_df['highest_edu']=gen_df[[\"edu_level_mother\", \"edu_level_father\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe with diversity scores\n",
    "div_df=pd.read_pickle('../distance/diversity_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb28b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matched pairs year 1\n",
    "sim_first=pd.read_pickle('../distance/results1.pkl')\n",
    "sim_first=sim_first[sim_first['distance'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matched pairs year 2\n",
    "sim_third=pd.read_pickle('../distance/results3.pkl')\n",
    "sim_third=sim_third[sim_third['distance'] < 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm for creating a progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a method to remove duplicate identifiers, keeping only one of each pair\n",
    "def remove_duplicate_identifiers(df, target):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sort the DataFrame by the target column in descending order\n",
    "    df.sort_values(target, ascending=False, inplace=True)\n",
    "    \n",
    "    # Drop duplicates based on the 'elev_id' column, keeping the first occurrence\n",
    "    df.drop_duplicates(subset=['elev_id'], keep='first', inplace=True)\n",
    "    \n",
    "    # Initialize a set to store unique student identifiers\n",
    "    unique_ids = set()\n",
    "    \n",
    "    # Initialize an empty mask list to keep track of unique rows\n",
    "    mask = []\n",
    "    \n",
    "    # Use tqdm to create a progress bar\n",
    "    progress_bar = tqdm(total=len(df), desc=\"Processing Rows\", unit=\"row\")\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        elev_id = row['elev_id']\n",
    "        neighbour = row['neighbour']\n",
    "        \n",
    "        # Check if either the elev_id or neighbour is not already in the set of unique IDs\n",
    "        if elev_id not in unique_ids and neighbour not in unique_ids:\n",
    "            # Add the student identifiers to the set of unique IDs\n",
    "            unique_ids.add(elev_id)\n",
    "            unique_ids.add(neighbour)\n",
    "            \n",
    "            # Append True to the mask list if the row is unique\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            # Append False to the mask list if the row is a duplicate\n",
    "            mask.append(False)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    # Close the progress bar\n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Create a boolean mask based on the unique rows\n",
    "    mask = np.array(mask)\n",
    "    \n",
    "    # Use the mask to select the unique rows\n",
    "    unique_df = df[mask]\n",
    "    return unique_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d4a8b",
   "metadata": {},
   "source": [
    "### First experiment\n",
    "Test if teaching competencies have an impact on performance of students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to calculate the ratio standard error\n",
    "def calculate_ratio_se(data_x, data_y):\n",
    "    # Calculate the mean and variance of the first column\n",
    "    mean_x = np.mean(data_x)\n",
    "    var_x = np.var(data_x)\n",
    "\n",
    "    # Calculate the mean and variance of the second column\n",
    "    mean_y = np.mean(data_y)\n",
    "    var_y = np.var(data_y)\n",
    "\n",
    "    # Calculate the sample sizes\n",
    "    n_x = len(data_x)\n",
    "    n_y = len(data_y)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((var_x / n_x**2) + (var_y / n_y**2))\n",
    "\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for evaluating regresion on grade \n",
    "def eval_regression_grade(df,col_x,col_y,dependent_x,dependent_y,threshold):\n",
    "    df = df.copy()\n",
    "    std_diff = np.std(df[col_x])\n",
    "    # Create a mask for the rows where competencies_y is higher than competencies_x\n",
    "    mask = df[col_x] < df[col_y]\n",
    "\n",
    "    # Swap the values between grade_x and grade_y in the specified rows\n",
    "    df.loc[mask, [dependent_x, dependent_y]] = df.loc[mask, [dependent_y, dependent_x]].values\n",
    "\n",
    "    # Swap the values between elev_id and neighbour_id in the specified rows\n",
    "    df.loc[mask, [col_x, col_y]] = df.loc[mask, [col_y,col_x]].values\n",
    "\n",
    "\n",
    "    # Swap the values between elev_id and neighbour_id in the specified rows\n",
    "    df.loc[mask, ['elev_id', 'neighbour']] = df.loc[mask, ['neighbour', 'elev_id']].values\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create a mask for the rows that meet the threshold in standardized bias\n",
    "    mask = np.abs(df[col_x] - df[col_y]) / std_diff > threshold\n",
    "    \n",
    "    mean_diff=df[dependent_x].mean()-df[dependent_y].mean()\n",
    "    # Apply the mask to filter the dataframe\n",
    "    df = df[mask]\n",
    "    \n",
    "    # Perform the paired t-test\n",
    "    t_stat, p_value = stats.ttest_rel(df[dependent_x], df[dependent_y])\n",
    "    print('\\n _______________________________________________________ \\n')\n",
    "    print('Standard Deviation: ', std_diff)\n",
    "    # Print the t-statistic and p-value\n",
    "    print('Number of comparisons', len(df))\n",
    "    print('t-statistic:', t_stat)\n",
    "    print('p-value:', p_value)\n",
    "    print('Mean difference in Dependent: ', mean_diff)\n",
    "    print('Ratio: ',df[dependent_x].mean() / df[dependent_y].mean())\n",
    "    ratio=df[dependent_x].mean() / df[dependent_y].mean()\n",
    "    ratio_error = calculate_ratio_se(df[dependent_x],df[dependent_y])\n",
    "    print('Ratio se: ',ratio_error)\n",
    "\n",
    "    \n",
    "    \n",
    "    return p_value,ratio,ratio_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20974c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to iterate the eval regression function and create plots for low and high parental education \n",
    "def iterate_thresholds(df, col_x, col_y, dependent_x, dependent_y,filename):\n",
    "    # Define the start of the thresholds\n",
    "    threshold = 0.2\n",
    "\n",
    "    # Segment your data into high and low parental education\n",
    "    high_edu = df[df['highest_edu_x'] > 0]\n",
    "    low_edu = df[df['highest_edu_x'] < 0]\n",
    "\n",
    "    # Create lists to store the thresholds and corresponding ratios for each group\n",
    "    thresholds_high = []\n",
    "    ratios_high = []\n",
    "    thresholds_low = []\n",
    "    ratios_low = []\n",
    "    ratio_errors_high = []\n",
    "    ratio_errors_low = []\n",
    "\n",
    "\n",
    "    p_value_high = 0\n",
    "    p_value_low = 0\n",
    "\n",
    "    # Iterate through thresholds in increments of 0.2 until p-value > 0.05 for both groups\n",
    "    while p_value_high <= 0.05 or p_value_low <= 0.05:\n",
    "        print(\"The threshold is == __________\",threshold,\"_____________________\")\n",
    "        # Get the p-value and ratio for the high education group\n",
    "        if p_value_high <= 0.05:\n",
    "            p_value_high, ratio_high,ratio_error_high = eval_regression_grade(high_edu, col_x, col_y, dependent_x, dependent_y, threshold)\n",
    "            ratio_percent_high = (ratio_high - 1) * 100\n",
    "            if p_value_high <= 0.05:\n",
    "                thresholds_high.append(threshold)\n",
    "                ratios_high.append(ratio_high)\n",
    "                ratio_errors_high.append(ratio_error_high)\n",
    "\n",
    "        # Get the p-value and ratio for the low education group\n",
    "        if p_value_low <= 0.05:\n",
    "            p_value_low, ratio_low,ratio_error_low = eval_regression_grade(low_edu, col_x, col_y, dependent_x, dependent_y, threshold)\n",
    "            ratio_percent_low = (ratio_low - 1) * 100\n",
    "            if p_value_low <= 0.05:\n",
    "                thresholds_low.append(threshold)\n",
    "                ratios_low.append(ratio_low)\n",
    "                ratio_errors_low.append(ratio_error_low)\n",
    "\n",
    "        # Increase the threshold by 0.2 for the next iteration\n",
    "        threshold += 0.2\n",
    "    \n",
    "    # Plot the ratios for each threshold for both groups\n",
    "    plt.plot(thresholds_high, ratios_high, label='High Parental Education')\n",
    "    plt.plot(thresholds_low, ratios_low, label='Low Parental Education')\n",
    "\n",
    "    # Plot the ratios for each threshold for both groups with error bars\n",
    "    plt.errorbar(thresholds_high, ratios_high, yerr=ratio_errors_high, label=' ', color='blue')\n",
    "    plt.errorbar(thresholds_low, ratios_low, yerr=ratio_errors_low, label=' ', color='orange')\n",
    "\n",
    "    # Create custom legend handles with corresponding colors\n",
    "    handles = [plt.Line2D([], [], color='blue', label='High Parental Education (with error bars)'),\n",
    "               plt.Line2D([], [], color='orange', label='Low Parental Education (with error bars)')]\n",
    "\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Ratio Between Means in Dependent Variable')\n",
    "    plt.title('Ratio of Dependent Variable for Different Thresholds')\n",
    "    plt.legend(handles=handles)\n",
    "    plt.savefig('figures/{}.pdf'.format(filename), format='pdf')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge relevant columns with the pairwise students to calculate teacher effects\n",
    "merger=gen_df[['elev_id','step','grade','course','exam','Written','hard_science',\n",
    "               'competencies','students','avg_start','highest_edu','avg_start_scaled','level_A','level_B']].copy()\n",
    "#merger=merger[merger['income_father'] < 0]\n",
    "#Define the type of course we want to test\n",
    "merger=merger.query('hard_science == 0 & step >= 3 & exam == 1')\n",
    "\n",
    "merger.drop(columns=['hard_science'],inplace=True)\n",
    "\n",
    "compare = sim_third.merge(merger,on='elev_id')\n",
    "merger.rename(columns={'elev_id':'neighbour'},inplace=True)\n",
    "\n",
    "compare=compare.merge(merger,on='neighbour')\n",
    "\n",
    "\n",
    "compare=compare.loc[(compare['course_x'] == compare['course_y']) & (compare['Written_x'] == compare['Written_y']) & (compare['exam_x'] == compare['exam_y']) & (compare['level_A_x'] == compare['level_A_y'])  & (compare['level_B_x'] == compare['level_B_y'])]\n",
    "print(len(compare))\n",
    "\n",
    "compare['comp_diff']=abs(compare['competencies_x']-compare['competencies_y'])\n",
    "compare['size_diff']=abs(compare['students_x']-compare['students_y'])\n",
    "compare['grade_diff']=abs(compare['grade_x']-compare['grade_y'])\n",
    "compare['start_diff']=abs(abs(compare['avg_start_x'])-abs(compare['avg_start_y']))\n",
    "compare['start_diff_scaled']=abs(abs(compare['avg_start_scaled_x'])-abs(compare['avg_start_scaled_y']))\n",
    "compare['avg_start_x'] = abs(compare['avg_start_x'])\n",
    "compare['avg_start_y'] = abs(compare['avg_start_y'])\n",
    "#compare['impact_diff']=abs(compare['teacher_impact_x']-compare['teacher_impact_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impact of having course competent teacher\n",
    "competencies=compare.query('comp_diff > 0.2')\n",
    "competencies=remove_duplicate_identifiers(competencies,'comp_diff')\n",
    "\n",
    "low_edu=competencies[competencies['highest_edu_x'] < 0]    \n",
    "high_edu=competencies[competencies['highest_edu_x'] > 0]    \n",
    "\n",
    "\n",
    "print('Low Parental Education: ')\n",
    "low_edu_comp =eval_regression_grade(low_edu,'competencies_x','competencies_y','grade_x','grade_y',0.2)\n",
    "\n",
    "print('\\n\\n\\n\\nHigh Parental Education: ')\n",
    "high_edu_comp =eval_regression_grade(high_edu,'competencies_x','competencies_y','grade_x','grade_y',0.2)\n",
    "\n",
    "print('\\n\\n\\nTogether: ')\n",
    "high_edu_comp =eval_regression_grade(competencies,'competencies_x','competencies_y','grade_x','grade_y',0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266da9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impact of late or early starttime \n",
    "time=compare.query('start_diff_scaled > 1')\n",
    "\n",
    "time=remove_duplicate_identifiers(time,'start_diff_scaled')\n",
    "\n",
    "low_edu=time[time['highest_edu_x'] < 0]    \n",
    "high_edu=time[time['highest_edu_x'] > 0]    \n",
    "\n",
    "#Run for high and low edu and everyone\n",
    "start_time=eval_regression_grade(low_edu,'avg_start_scaled_x','avg_start_scaled_y','grade_x','grade_y',0.4)\n",
    "start_time=eval_regression_grade(high_edu,'avg_start_scaled_x','avg_start_scaled_y','grade_x','grade_y',0.4)\n",
    "start_time=eval_regression_grade(time,'avg_start_scaled_x','avg_start_scaled_y','grade_x','grade_y',0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Impact of larger group sizes test for more than 28 vs less than 28\n",
    "group_size=compare.query('(students_x > 28 & students_y < 28) | (students_x < 28 & students_y > 28)')\n",
    "\n",
    "group_size=remove_duplicate_identifiers(group_size,'size_diff')#Remove Duplicates\n",
    "low_edu=group_size[group_size['highest_edu_x'] < 0]#Low edu group    \n",
    "high_edu=group_size[group_size['highest_edu_x'] > 0]  #High edu group\n",
    "\n",
    "#Regression for both groups\n",
    "eval_regression_grade(low_edu, 'students_x','students_y','grade_x','grade_y',0.4)\n",
    "eval_regression_grade(high_edu, 'students_x','students_y','grade_x','grade_y',0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90247caa",
   "metadata": {},
   "source": [
    "### Second round of experiments\n",
    "See the impact of diversity in classroom on retention of students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify the evaluation of grades to fit the binary prediction of changing schools.By utilizing mcnemar\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "def eval_binary_grade(df, col_x, col_y, dependent_x, dependent_y, threshold):\n",
    "    df = df.copy()\n",
    "\n",
    "    mask = df[col_x] < df[col_y]\n",
    "\n",
    "    df.loc[mask, [dependent_x, dependent_y]] = df.loc[mask, [dependent_y, dependent_x]].values\n",
    "    df.loc[mask, [col_x, col_y]] = df.loc[mask, [col_y,col_x]].values\n",
    "    df.loc[mask, ['elev_id', 'neighbour']] = df.loc[mask, ['neighbour', 'elev_id']].values\n",
    "\n",
    "    mask = np.abs(df[col_x] - df[col_y]) > threshold\n",
    "\n",
    "    df = df[mask]\n",
    "\n",
    "    table = pd.crosstab(df[dependent_x], df[dependent_y])\n",
    "    \n",
    "    \n",
    "\n",
    "    result = mcnemar(table, exact=True)\n",
    "\n",
    "    print('\\n _______________________________________________________ \\n')\n",
    "    print('Number of comparisons', len(df))\n",
    "    print('statistic:', result.statistic)\n",
    "    print('p-value:', result.pvalue)\n",
    "    print('Proportion difference in dependent: ', df[dependent_x].mean() - df[dependent_y].mean())\n",
    "    print('Ratio: ',df[dependent_x].mean() / df[dependent_y].mean())\n",
    "    \n",
    "    print('\\nContingency Table:')\n",
    "    print(table.to_string())\n",
    "    \n",
    "    ratio_error = calculate_ratio_se(df[dependent_x],df[dependent_y])\n",
    "    print('Ratio se: ',ratio_error)\n",
    "\n",
    "\n",
    "    return result.pvalue, df[dependent_x].mean() / df[dependent_y].mean(), ratio_error\n",
    "\n",
    "#new iterate graph function for binary\n",
    "def iterate_binary (df, col_x, col_y, dependent_x, dependent_y,filename):\n",
    "    # Define the start of the thresholds\n",
    "    threshold = 0.05\n",
    "\n",
    "    # Segment your data into high and low parental education\n",
    "    high_edu = df[df['highest_edu_x'] > 0]\n",
    "    low_edu = df[df['highest_edu_x'] < 0]\n",
    "\n",
    "    # Create lists to store the thresholds and corresponding ratios for each group\n",
    "    thresholds_high = []\n",
    "    ratios_high = []\n",
    "    thresholds_low = []\n",
    "    ratios_low = []\n",
    "    ratio_errors_low = []\n",
    "    ratio_errors_high = []\n",
    "\n",
    "    p_value_high = 0\n",
    "    p_value_low = 0\n",
    "\n",
    "    # Iterate through thresholds in increments of 0.2 until p-value > 0.05 for both groups\n",
    "    while p_value_high <= 0.05 or p_value_low <= 0.05:\n",
    "        print(\"The threshold is == __________\",threshold,\"_____________________\")\n",
    "        # Get the p-value and ratio for the high education group\n",
    "        if p_value_high <= 0.05:\n",
    "            p_value_high, ratio_high, ratio_error_high = eval_binary_grade(high_edu, col_x, col_y, dependent_x, dependent_y, threshold)\n",
    "            #ratio_percent_high = (ratio_high - 1) * 100\n",
    "            if p_value_high <= 0.05:\n",
    "                thresholds_high.append(threshold)\n",
    "                ratios_high.append(ratio_high)\n",
    "                ratio_errors_high.append(ratio_error_high)\n",
    "\n",
    "\n",
    "        # Get the p-value and ratio for the low education group\n",
    "        if p_value_low <= 0.05:\n",
    "            p_value_low, ratio_low,ratio_error_low = eval_binary_grade(low_edu, col_x, col_y, dependent_x, dependent_y, threshold)\n",
    "            #ratio_percent_low = (ratio_low - 1) * 100\n",
    "            if p_value_low <= 0.05:\n",
    "                thresholds_low.append(threshold)\n",
    "                ratios_low.append(ratio_low)\n",
    "                ratio_errors_low.append(ratio_error_low)\n",
    "\n",
    "        # Increase the threshold by 0.2 for the next iteration\n",
    "        threshold += 0.02\n",
    "\n",
    "       # Plot the ratios for each threshold for both groups\n",
    "    plt.plot(thresholds_high, ratios_high, label='High Parental Education')\n",
    "    plt.plot(thresholds_low, ratios_low, label='Low Parental Education')\n",
    "\n",
    "    # Plot the ratios for each threshold for both groups with error bars\n",
    "    plt.errorbar(thresholds_high, ratios_high, yerr=ratio_errors_high, label=' ', color='blue')\n",
    "    plt.errorbar(thresholds_low, ratios_low, yerr=ratio_errors_low, label=' ', color='orange')\n",
    "\n",
    "    # Create custom legend handles with corresponding colors\n",
    "    handles = [plt.Line2D([], [], color='blue', label='High Parental Education'),\n",
    "               plt.Line2D([], [], color='orange', label='Low Parental Education')]\n",
    "\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Ratio Between Means in Dependent Variable')\n",
    "    plt.title('Ratio of Changing Schools for Different Thresholds')\n",
    "    plt.legend(handles=handles)\n",
    "    plt.savefig('figures/{}.pdf'.format(filename), format='pdf')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create encoding for depart reason in \n",
    "non_final = div_df.query('step != 3')\n",
    "# Get the one-hot encoding of the 'depart_reason' column\n",
    "one_hot = pd.get_dummies(non_final['depart_reason'])\n",
    "\n",
    "# Rename the columns of the one-hot encoded DataFrame\n",
    "one_hot.rename(columns={\n",
    "    21 :'next_step',\n",
    "    11: 'drop_out',\n",
    "    20: \"break_same_school\",\n",
    "    31: 'change_school',\n",
    "    30: 'break_change_school'\n",
    "}, inplace=True)\n",
    "\n",
    "# Concatenate the one-hot encoded DataFrame with the original DataFrame and drop original column\n",
    "non_final = pd.concat([non_final, one_hot], axis=1)\n",
    "#non_final.drop(columns=['depart_reason'],inplace=True)\n",
    "# Create a new column that checks if any of the dummy variables are equal to 1\n",
    "non_final['any_dummy'] = non_final[['drop_out', 'break_same_school', 'change_school', 'break_change_school']].any(axis=1).astype(int)\n",
    "\n",
    "\n",
    "#Create seperate for each step\n",
    "df_first=non_final.loc[non_final['step'] == 1].copy()\n",
    "df_second=non_final.loc[non_final['step'] == 2].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17427e7d",
   "metadata": {},
   "source": [
    "### Relationship between changing school and diversity for pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create mean difference on socio economic variables\n",
    "df_first['mean_diff']=(df_first['diff_edu_father']+df_first['diff_edu_mother']+\n",
    "                     df_first['diff_income_father'] + df_first['diff_income_mother']) / 4\n",
    "#Create mean difference on socio economic variables\n",
    "df_second['mean_diff']=(df_second['diff_edu_father']+df_second['diff_edu_mother']+\n",
    "                     df_second['diff_income_father'] + df_second['diff_income_mother']) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge metadata to the student pairs to calc difference between them\n",
    "test=df_first[['elev_id','diversity_score','drop_out','break_change_school','change_school','diff_age','mean_diff']].copy()\n",
    "reg_first=sim_first.merge(test,on='elev_id',how='left')\n",
    "print(len(sim_first),len(reg_first))\n",
    "print(len(reg_first[reg_first['diversity_score'].isna()]) / len(reg_first))\n",
    "test.rename(columns={'elev_id':'neighbour'},inplace=True)\n",
    "reg_first=reg_first.merge(test,on='neighbour',how='left')\n",
    "print(len(reg_first))\n",
    "\n",
    "reg_first['diversity_diff']=abs(reg_first['diversity_score_x']-reg_first['diversity_score_y'])\n",
    "\n",
    "\n",
    "reg_first.dropna(inplace=True)\n",
    "\n",
    "#Merge parents socio economic status\n",
    "parents_socio=gen_df[['elev_id','highest_edu']].copy()\n",
    "parents_socio.drop_duplicates(inplace=True)\n",
    "print(len(reg_first))\n",
    "reg_first=reg_first.merge(parents_socio,on='elev_id',how='left')\n",
    "print(len(socio_compare))\n",
    "parents_socio.rename(columns={'elev_id':'neighbour'},inplace=True)\n",
    "reg_first=reg_first.merge(parents_socio,on='neighbour',how='left')\n",
    "print(len(socio_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18019d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "test=remove_duplicate_identifiers(reg_first,'diversity_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dacc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate impact of diversity\n",
    "changing=eval_binary_grade(test,'diversity_score_x','diversity_score_y','change_school_x','change_school_y',0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dab3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create graph with increased threshold in diversity for retention\n",
    "plt.rcParams['text.usetex'] = False\n",
    "iterate_binary(test,'diversity_score_x','diversity_score_y','change_school_x','change_school_y','diversity_retention')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fab4a",
   "metadata": {},
   "source": [
    "### See the general tendency of not progressing to next school year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of bins\n",
    "num_bins = 20\n",
    "\n",
    "first_retention = df_first.query('mean_diff < 1.4 & mean_diff > -1.4')\n",
    "\n",
    "print(len(first_retention)/len(df_first))\n",
    "\n",
    "# Bin the 'mean_diff' values\n",
    "first_retention['mean_diff_bins'] = pd.cut(first_retention['mean_diff'], bins=num_bins)\n",
    "\n",
    "# Calculate the mean of 'mean_diff' for each bin\n",
    "bin_means = first_retention.groupby('mean_diff_bins')['mean_diff'].mean()\n",
    "\n",
    "# Calculate the percentage of 'change_school' and 'dropout' for each bin\n",
    "bin_change_school_perc = first_retention.groupby('mean_diff_bins')['change_school'].mean() * 100\n",
    "bin_dropout_perc = first_retention.groupby('mean_diff_bins')['drop_out'].mean() * 100\n",
    "\n",
    "# Calculate the width of the bars\n",
    "bar_width = 1.5 / num_bins  # Adjust the value as needed\n",
    "\n",
    "# Calculate the positions of the bars for 'change_school' and 'dropout'\n",
    "bar_positions_change_school = bin_means - bar_width/2\n",
    "bar_positions_dropout = bin_means + bar_width/2\n",
    "\n",
    "# Create the bar plot with thinner bars for 'change_school'\n",
    "plt.bar(bar_positions_change_school, bin_change_school_perc, align='center', alpha=0.8, color='steelblue', width=bar_width, label='Change School')\n",
    "\n",
    "# Create the bar plot with thinner bars for 'dropout'\n",
    "plt.bar(bar_positions_dropout, bin_dropout_perc, align='center', alpha=0.8, color='orange',width=bar_width, label='Dropout')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Difference in socio-economic status compared to classmates')\n",
    "plt.ylabel('Percentage of students')\n",
    "plt.title('Percentage of Students not Continuing in Class by Mean Socio-economic Difference')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/retention_socio_difference.pdf',dpi=400,bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff97e4",
   "metadata": {},
   "source": [
    "### Work on exploring how peers might lift students to overachieve \n",
    "\n",
    "Using student pairs see impact of one being higher or lower social status than peers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pairs withtout matching on average grade\n",
    "df_grade=pd.read_pickle('../distance/no_grade.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create very small difference - identical\n",
    "df_grade=df_grade[df_grade['distance']<0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01661d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the diversity dataframe to see how they stack up to peers\n",
    "merge_grade=div_df[div_df['step'] == 3].drop(columns=['step','join_reason','depart_reason','inst_nr'])\n",
    "print(len(df_grade))\n",
    "grade_compare=df_grade.merge(merge_grade,on='elev_id',how='left')\n",
    "print(len(grade_compare))\n",
    "#Merge for neighbour\n",
    "merge_grade.rename(columns={'elev_id':'neighbour'},inplace=True)\n",
    "grade_compare=grade_compare.merge(merge_grade,on='neighbour')\n",
    "print(len(grade_compare))\n",
    "\n",
    "grade_compare.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbedac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create diff between all socio for each of the pairs\n",
    "grade_compare['mom_income_diff']=grade_compare['diff_income_mother_x']-grade_compare['diff_income_mother_y']\n",
    "grade_compare['dad_income_diff']=grade_compare['diff_income_father_x']-grade_compare['diff_income_father_y']\n",
    "grade_compare['mom_edu_diff']=grade_compare['diff_edu_mother_x']-grade_compare['diff_edu_mother_y']\n",
    "grade_compare['dad_edu_diff']=grade_compare['diff_edu_father_x']-grade_compare['diff_edu_father_y']\n",
    "grade_compare['students_avg_grade_diff']=grade_compare['students_avg_grade_x']-grade_compare['students_avg_grade_y']\n",
    "\n",
    "#Socio is the average difference\n",
    "grade_compare['socio_x']=grade_compare['diff_edu_father_x'] + grade_compare['diff_edu_mother_x'] + grade_compare['diff_income_mother_x'] + grade_compare['diff_income_father_x']\n",
    "grade_compare['socio_y']=grade_compare['diff_edu_father_y'] + grade_compare['diff_edu_mother_y'] + grade_compare['diff_income_mother_y'] + grade_compare['diff_income_father_y']\n",
    "\n",
    "\n",
    "#Inverse to ensure that students with positive values are surrounded by peers of higher socio-economic statuts\n",
    "grade_compare['socio_inverse_x']=grade_compare['socio_x']*(-1)\n",
    "grade_compare['socio_inverse_y']=grade_compare['socio_y']*(-1)\n",
    "grade_compare['socio_diff']=abs(grade_compare['socio_x'] - grade_compare['socio_y'])\n",
    "\n",
    "#Select only relevant columns for the experiment\n",
    "soc_diff=grade_compare[['elev_id','neighbour','socio_x','socio_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56aa9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge so we ensure that we get highest edu as well - we only need for one since the edu will be the same for pairs\n",
    "parents_socio=gen_df[['elev_id','highest_edu']].copy()\n",
    "parents_socio.drop_duplicates(inplace=True)\n",
    "print(len(grade_compare))\n",
    "socio_compare=grade_compare.merge(parents_socio,on='elev_id',how='left')\n",
    "print(len(socio_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the duplicates in the pair matching\n",
    "socio=remove_duplicate_identifiers(socio_compare,'socio_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate impact of being in higher social status group\n",
    "low_socio_diff=eval_regression_grade(socio.query('highest_edu_x < 0'),'socio_inverse_x','socio_inverse_y','avg_grade_x','avg_grade_y',0.2)\n",
    "high_socio_diff=eval_regression_grade(socio.query('highest_edu_x > 0'),'socio_inverse_x','socio_inverse_y','avg_grade_x','avg_grade_y',0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a334205",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_thresholds(socio,'socio_inverse_x','socio_inverse_y','avg_grade_x','avg_grade_y','socio_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for evaluating regresion on grade \n",
    "def return_sorted(df,col_x,col_y,dependent_x,dependent_y):\n",
    "    df = df.copy()\n",
    "    std_diff = np.std(df[col_x])\n",
    "    # Create a mask for the rows where competencies_y is higher than competencies_x\n",
    "    mask = df[col_x] < df[col_y]\n",
    "\n",
    "    # Swap the values between grade_x and grade_y in the specified rows\n",
    "    df.loc[mask, [dependent_x, dependent_y]] = df.loc[mask, [dependent_y, dependent_x]].values\n",
    "\n",
    "    # Swap the values between elev_id and neighbour_id in the specified rows\n",
    "    df.loc[mask, [col_x, col_y]] = df.loc[mask, [col_y,col_x]].values\n",
    "\n",
    "\n",
    "    # Swap the values between elev_id and neighbour_id in the specified rows\n",
    "    df.loc[mask, ['elev_id', 'neighbour']] = df.loc[mask, ['neighbour', 'elev_id']].values\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4740b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find only pairs where one is better off than peers and one is worse off\n",
    "sorted_socio=return_sorted(socio,'socio_inverse_x','socio_inverse_y','avg_grade_x','avg_grade_y')\n",
    "sorted_socio=sorted_socio.query('socio_inverse_x > 0 & socio_inverse_y < 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find difference between the better and worse off\n",
    "print(sorted_socio['avg_grade_x'].mean()),print(sorted_socio['avg_grade_y'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test to see if the difference is statistically significant\n",
    "t_stat, p_val = stats.ttest_ind(sorted_socio['avg_grade_x'], sorted_socio['avg_grade_y'])\n",
    "\n",
    "print(f\"t-statistic: {t_stat}\")\n",
    "print(f\"p-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3b36c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
